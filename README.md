# Table of Contents

- [🛡️ Phishing Email Detection with Explainable AI](#🛡️-phishing-email-detection-with-explainable-ai)
- [📁 Files](#-files)
- [📌 Project Overview](#-project-overview)
- [📊 Dataset](#-dataset)
- [🧠 Models](#-models)
  - [🔹 MLP (TF-IDF + Feedforward Neural Network)](#-mlp)
  - [🔹 RoBERTa (Transformer Fine-tuning)](#-roberta)
- [⚙️ Training Pipeline](#️-training-pipeline)
- [📈 Performance Summary](#-performance-summary)
- [💡 Future Work: Explainability (XAI)](#-future-work)
- [📎 Repository Structure](#-repository-structure)

---

# 🛡️ Phishing Email Detection with Explainable AI


> **Safe AI Project Proposal**
> **Team 5 [ExplainSec]**   
> **20202905 Hyunmin Park (박현민)**   
> **20200397 Seungjun You (유승준)**   


This repository contains two machine learning models for detecting phishing emails, focusing on interpretability and robustness. The project compares a traditional MLP model with a state-of-the-art Transformer-based model (RoBERTa) using a real-world phishing dataset.

## 📁 Files
- [`mlp.ipynb`](mlp.ipynb): Implements a lightweight and interpretable **Multilayer Perceptron (MLP)** model trained on TF-IDF vectors. The file provides detailed explanations of training, validation, and evaluation processes.
- [`roberta.ipynb`](roberta.ipynb): Fine-tunes a **pretrained RoBERTa** model from Hugging Face for phishing email classification. The file includes comprehensive descriptions of the training, validation, and evaluation steps.
- [`mlp_best.pt`](mlp_best.pt): **Saved model** for the MLP.  
- [`roberta-best.pt`](roberta-best.pt): **Saved model** for the fine-tuned RoBERTa.  
> **Note:** The RoBERTa model file (`roberta-best.pt`) is about 500MB and has been uploaded separately to eClass due to its large size.

## 📌 Project Overview

Phishing emails have become increasingly sophisticated, often generated by AI models like ChatGPT. To combat these threats, we need not only accurate detectors but also **explainable models** that help human analysts understand why an email was flagged.

Our goal: **Build high-performing phishing detectors with explainability in mind.**

## 📊 Dataset

- Source: [Kaggle - Phishing Emails Dataset](https://www.kaggle.com/datasets/subhajournal/phishingemails)
- Samples: 18,650 emails (both phishing and legitimate)
- Task: Binary classification (1 = Safe, 0 = Phishing)  
  **(safe=1, phishing=0)**

## 🧠 Models

### 🔹 MLP 
- TF-IDF + Feedforward Neural Network
- Input: TF-IDF vectors
- Architecture: [128] → [64] → [1] (Sigmoid)
- Techniques: Dropout (0.4), L2 regularization, EarlyStopping
- Framework: PyTorch
- Threshold tuned to 0.45 for improved recall

### 🔹 RoBERTa 
- Transformer Fine-tuning
- Input: Raw text tokenized via `RobertaTokenizer`
- Base model: `roberta-base` from Hugging Face
- Output: Binary classification using `[CLS]` token
- Optimization: `AdamW`, EarlyStopping based on validation accuracy
- Framework: Transformers (Hugging Face) + PyTorch

## ⚙️ Training Pipeline

1. **Preprocessing**: Clean text, drop nulls/duplicates, label encode (safe=1, phishing=0)
2. **Feature Engineering**:
   - MLP → TF-IDF vectorization
   - RoBERTa → BPE tokenization
3. **Data Split**: 60% train / 20% val / 20% test (Stratified)
4. **Training**: Custom training loops with early stopping
5. **Evaluation**: Accuracy, F1-score, Confusion Matrix, Threshold tuning

## 📈 Performance Summary

| Model   | Precision        | Recall       | F1 Score |
|---------|------------------|--------------|----------|
| MLP     | 0.96             | 0.98         | 0.96     |
| RoBERTa | 0.98             | 0.98         | 0.98     |

## 💡 Future Work 

- Explainability (XAI)

We plan to apply SHAP and LIME to visualize how each model arrives at its decisions. This will:
- Highlight key words influencing classification
- Compare decision logic between MLP and RoBERTa
- Evaluate whether explanations are actionable for analysts

## 📎 Repository Structure

📦 phishing-email-detection/    
├── 📄 README.md                # Project description document   
├── 📄 Phishing_Email.csv       # Original dataset from Kaggle   
├── 📄 mlp.ipynb                # TF-IDF based MLP model training notebook    
├── 📄 roberta.ipynb            # RoBERTa model fine-tuning notebook   
├── 📄 mlp_best.pt              # Trained MLP model    
├── 📄 roberta_best.pt          # Trained RoBERTa model **(file is large, available separately on eClass)**    

---

# 🛡️ 설명 가능한 AI 기반 피싱 이메일 탐지

이 저장소는 피싱 이메일을 탐지하기 위한 두 가지 머신러닝 모델을 포함하고 있으며, 해석 가능성과 견고성에 중점을 두고 있습니다. 본 프로젝트는 실제 피싱 이메일 데이터셋을 활용하여 전통적인 MLP 모델과 최신 트랜스포머 기반 RoBERTa 모델의 성능을 비교합니다.

## 📁 파일 구성
- [`mlp.ipynb`](mlp.ipynb): TF-IDF 벡터를 기반으로 학습된 **경량화 및 해석 가능한 MLP(다층 퍼셉트론)** 모델을 구현합니다. 이 파일에는 학습, 검증, 평가 과정이 자세히 설명되어 있습니다.
- [`roberta.ipynb`](roberta.ipynb): Hugging Face의 사전학습된 **RoBERTa** 모델을 피싱 이메일 분류에 맞게 미세조정합니다. 이 파일에는 학습, 검증, 평가 절차가 상세하게 안내되어 있습니다.
- [`mlp_best.pt`](mlp_best.pt): **MLP 모델이 저장된 파일**입니다.  
- [`roberta-best.pt`](roberta-best.pt): **미세조정된 RoBERTa 모델이 저장된 파일**입니다.  
> **참고:** RoBERTa 모델 파일(`roberta-best.pt`)은 약 500MB로, 파일 크기가 커서 eClass에 별도로 업로드되었습니다.

## 📌 프로젝트 개요

최근 피싱 이메일은 ChatGPT와 같은 AI 모델로 생성되는 등 점점 더 정교해지고 있습니다. 이러한 위협에 대응하기 위해서는 단순히 정확한 탐지기뿐만 아니라, 이메일이 왜 탐지되었는지 인간 분석가가 이해할 수 있도록 **설명 가능한 모델**이 필요합니다.

우리의 목표: **설명 가능성을 갖춘 고성능 피싱 탐지기 개발**

## 📊 데이터셋

- 출처: [Kaggle - Phishing Emails Dataset](https://www.kaggle.com/datasets/subhajournal/phishingemails)
- 샘플 수: 18,650개 이메일(피싱 및 정상 포함)
- 태스크: 이진 분류 (1 = 정상, 0 = 피싱)  
  **(safe=1, phishing=0)**

## 🧠 모델

### 🔹 MLP 
- TF-IDF + 피드포워드 신경망
- 입력: TF-IDF 벡터
- 아키텍처: [128] → [64] → [1] (시그모이드)
- 기법: 드롭아웃(0.4), L2 정규화, EarlyStopping
- 프레임워크: PyTorch
- 임계값(threshold) 0.45로 리콜 향상

### 🔹 RoBERTa 
- 트랜스포머 파인튜닝
- 입력: `RobertaTokenizer`로 토크나이즈된 원본 텍스트
- 기반 모델: Hugging Face의 `roberta-base`
- 출력: `[CLS]` 토큰을 활용한 이진 분류
- 최적화: `AdamW`, 검증 정확도 기반 EarlyStopping
- 프레임워크: Transformers(Hugging Face) + PyTorch

## ⚙️ 학습 파이프라인

1. **전처리**: 텍스트 정제, 결측/중복 제거, 라벨 인코딩 (정상=1, 피싱=0)
2. **특성 엔지니어링**:
   - MLP → TF-IDF 벡터화
   - RoBERTa → BPE 토크나이즈
3. **데이터 분할**: 학습 60% / 검증 20% / 테스트 20% (층화 추출)
4. **학습**: EarlyStopping이 적용된 커스텀 학습 루프
5. **평가**: 정확도, F1-score, 혼동행렬, 임계값 튜닝

## 📈 성능 요약

| 모델    | 정밀도 | 재현율 | F1 점수 |
|---------|--------------|-------------|---------|
| MLP     | 0.96         | 0.98        | 0.96    |
| RoBERTa | 0.98         | 0.98        | 0.98    |

## 💡 향후 계획 

- 설명 가능한 인공지능(XAI)

SHAP 및 LIME을 적용하여 각 모델이 어떻게 의사결정을 내리는지 시각화할 예정입니다. 이를 통해:
- 분류에 영향을 미치는 주요 단어를 하이라이트
- MLP와 RoBERTa의 의사결정 논리 비교
- 분석가가 활용 가능한 설명인지 평가

## 📎 저장소 구조

📦 phishing-email-detection/      
├── 📄 README.md                # 프로젝트 설명 문서   
├── 📄 Phishing_Email.csv       # Kaggle에서 받은 원본 데이터셋   
├── 📄 mlp.ipynb                # TF-IDF 기반 MLP 모델 학습 노트북  
├── 📄 roberta.ipynb            # RoBERTa 모델 파인튜닝 노트북  
├── 📄 mlp_best.pt              # 학습된 MLP 모델   
├── 📄 roberta_best.pt          # 학습된 RoBERTa 모델 가중치 (용량이 커서 Eclass에 업로드함)   